{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 1, 400]\n[4, 120, 400]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from collections import namedtuple\n",
    "HParams = namedtuple('HParams',\n",
    "                     'mode, min_lr, lr, batch_size, '\n",
    "                     'enc_layers, enc_timesteps, dec_timesteps, '\n",
    "                     'min_input_len, num_hidden, emb_dim, max_grad_norm, '\n",
    "                     'num_softmax_samples')\n",
    "hps = HParams(\n",
    "      mode=\"train\",  # train, eval, decode\n",
    "      min_lr=0.01,  # min learning rate.\n",
    "      lr=0.15,  # learning rate\n",
    "      batch_size=4,\n",
    "      enc_layers=4,\n",
    "      enc_timesteps=120,\n",
    "      dec_timesteps=30,\n",
    "      min_input_len=2,  # discard articles/summaries < than this\n",
    "      num_hidden=200,  # for rnn cell\n",
    "      emb_dim=128,  # If 0, don't use embedding\n",
    "      max_grad_norm=2,\n",
    "      num_softmax_samples=4096)  # If 0, no sampled softmax.\n",
    "_articles = tf.placeholder(tf.int32,\n",
    "                                    [hps.batch_size, hps.enc_timesteps],\n",
    "                                    name='articles')\n",
    "encoder_inputs = tf.unstack(tf.transpose(_articles))\n",
    "vsize=4000\n",
    "embedding = tf.get_variable(\n",
    "            'embedding', [vsize, hps.emb_dim], dtype=tf.float32,\n",
    "            initializer=tf.truncated_normal_initializer(stddev=1e-4))\n",
    "\n",
    "emb_encoder_inputs = [tf.nn.embedding_lookup(embedding, x)\n",
    "                              for x in encoder_inputs]\n",
    "article_lens = tf.placeholder(tf.int32, [hps.batch_size],\n",
    "                                        name='article_lens')\n",
    "print(emb_encoder_inputs[0].get_shape().as_list())\n",
    "num_hidden=200\n",
    "for layer_i in range(hps.enc_layers):\n",
    "    with tf.variable_scope('encoder%d' % layer_i):\n",
    "        cell_fw = tf.nn.rnn_cell.LSTMCell(\n",
    "            num_hidden,\n",
    "            initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=123),\n",
    "            state_is_tuple=True)\n",
    "        cell_bw = tf.nn.rnn_cell.LSTMCell(\n",
    "            num_hidden,\n",
    "            initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=113),\n",
    "            state_is_tuple=True)\n",
    "        # emb_encoder_inputs的shape是[batch_size,2*num_hidden]\n",
    "        (emb_encoder_inputs, fw_state, _) = tf.nn.static_bidirectional_rnn(\n",
    "            cell_fw, cell_bw, emb_encoder_inputs, dtype=tf.float32,\n",
    "            sequence_length=article_lens)\n",
    "print(emb_encoder_inputs[0].get_shape().as_list())\n",
    "encoder_outputs = emb_encoder_inputs\n",
    "encoder_outputs = [tf.reshape(x, [hps.batch_size, 1, 2*hps.num_hidden]) for x in encoder_outputs]\n",
    "print(encoder_outputs[0].get_shape().as_list())\n",
    "enc_top_states = tf.concat(axis=1, values=encoder_outputs)\n",
    "print(enc_top_states.get_shape().as_list())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
